{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a54a0e45",
   "metadata": {},
   "source": [
    "# ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c7ef9c",
   "metadata": {},
   "source": [
    "The Alternating Least Squares (ALS) model is a popular collaborative filtering technique used for building recommender systems. It is particularly effective for handling large-scale data and sparse user-item matrices. ALS works by factorizing the user-item interaction matrix into two lower-dimensional matrices: one for users and one for items.\n",
    "\n",
    "The key idea behind ALS is to alternate between optimizing the user matrix and the item matrix, fixing one while solving for the other using a least squares approach. This process continues iteratively until convergence, producing predictions for unseen user-item interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1628103",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5b476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "DATA_FOLDER=\"../data\"\n",
    "if [ ! -d \"$DATA_FOLDER\" ]; then\n",
    "    wget --no-check-certificate \"https://drive.usercontent.google.com/download?id=1qe5hOSBxzIuxBb1G_Ih5X-O65QElollE&export=download&confirm=t&uuid=b2002093-cc6e-4bd5-be47-9603f0b33470\" -O KuaiRec.zip\n",
    "    unzip KuaiRec.zip -d \"$DATA_FOLDER\"\n",
    "    rm KuaiRec.zip\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871c6943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b1adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "# Using the small matrix because the big_matrix makes spark run out of memory.\n",
    "data = \"../data/KuaiRec 2.0/data\"\n",
    "interactions = pd.read_csv(f\"{data}/small_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ff38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless data.\n",
    "interactions = interactions.dropna()\n",
    "interactions = interactions.drop_duplicates()\n",
    "interactions = interactions[interactions[\"timestamp\"] >= 0]\n",
    "\n",
    "# Drop useless columns.\n",
    "interactions.drop(columns=[\"play_duration\", \"video_duration\", \"time\", \"date\", \"timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae8f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/16 22:28:52 WARN Utils: Your hostname, Amines-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.188.64.109 instead (on interface en0)\n",
      "25/05/16 22:28:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/16 22:28:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/16 22:29:07 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# Setup Spark.\n",
    "spark = SparkSession.builder.appName(\"ALS Recommender System\").getOrCreate()\n",
    "spark_df = spark.createDataFrame(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf20852",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc719833",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"video_id\",\n",
    "    ratingCol=\"watch_ratio\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4340261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/16 22:29:33 WARN TaskSetManager: Stage 0 contains a task of very large size (7334 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/16 22:29:37 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 0 (TID 0): Attempting to kill Python Worker\n",
      "25/05/16 22:29:37 WARN TaskSetManager: Stage 1 contains a task of very large size (7334 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/16 22:29:42 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/05/16 22:29:42 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "25/05/16 22:29:42 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "25/05/16 22:29:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/05/16 22:29:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/05/16 22:29:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/05/16 22:29:46 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/05/16 22:29:46 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/05/16 22:29:46 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/05/16 22:29:46 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/05/16 22:29:46 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/05/16 22:29:46 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    }
   ],
   "source": [
    "model = als.fit(spark_df)\n",
    "\n",
    "model_path = \"als_model\"\n",
    "\n",
    "# Delete model if it exists.\n",
    "if os.path.exists(model_path) and os.path.isdir(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e825a799",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a52f00c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+\n",
      "|user_id|video_id|prediction|\n",
      "+-------+--------+----------+\n",
      "|   7162|    6523| 1.3845127|\n",
      "+-------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recommend video 6523 for user 7162.\n",
    "user_item_df = spark.createDataFrame([Row(user_id=7162, video_id=6523)], [\"user_id\", \"video_id\"])\n",
    "predictions = model.transform(user_item_df)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea128242",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b44a3da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/16 22:29:47 WARN TaskSetManager: Stage 183 contains a task of very large size (7334 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/16 22:29:50 WARN TaskSetManager: Stage 242 contains a task of very large size (7334 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/16 22:29:54 WARN TaskSetManager: Stage 301 contains a task of very large size (7334 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Model Evaluation Metrics:\n",
      "‚û°Ô∏è  MAE  (Mean Absolute Error)    : 0.3515\n",
      "‚û°Ô∏è  RMSE (Root Mean Squared Error): 1.2322\n",
      "‚û°Ô∏è  R¬≤ Score                      : 0.1748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(spark_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"watch_ratio\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"watch_ratio\", predictionCol=\"prediction\")\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"r2\", labelCol=\"watch_ratio\", predictionCol=\"prediction\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"üìä Model Evaluation Metrics:\")\n",
    "print(f\"‚û°Ô∏è  MAE  (Mean Absolute Error)    : {round(mae, 4)}\")\n",
    "print(f\"‚û°Ô∏è  RMSE (Root Mean Squared Error): {round(rmse, 4)}\")\n",
    "print(f\"‚û°Ô∏è  R¬≤ Score                      : {round(r2, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6bdcaf",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we implemented and evaluated an **ALS (Alternating Least Squares)** model for collaborative filtering. The ALS algorithm is widely used for building recommendation systems by factorizing the user-item interaction matrix into latent factors.\n",
    "\n",
    "#### Insights from the Evaluation:\n",
    "- **MAE**: The **Mean Absolute Error** of **0.3515** indicates the average magnitude of error between the predicted ratings and actual ratings. A lower MAE suggests better accuracy, though there is still room for improvement in fine-tuning the model.\n",
    "  \n",
    "- **RMSE**: The **Root Mean Squared Error** of **1.2322** highlights the model's deviation from actual ratings. RMSE is more sensitive to large errors, and while the value here suggests reasonable predictive performance, further optimization may reduce it.\n",
    "\n",
    "- **R¬≤ Score**: The **R¬≤ Score** of **0.1748** implies that the model is able to explain around 17.5% of the variance in the actual ratings. This suggests that while the ALS model captures some of the patterns in the data, there is significant room for improvement in terms of how much variance it can explain.\n",
    "\n",
    "The **ALS model** demonstrates moderate performance based on the evaluation metrics, with an acceptable **MAE** and **RMSE**, but there is potential to improve both **accuracy** and **coverage** by tuning hyperparameters.\n",
    "\n",
    "Overall, the ALS model is a useful starting point for collaborative filtering tasks, but further optimization is needed to achieve better generalization and more accurate recommendations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
